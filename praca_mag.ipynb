{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy notatnik jest integralną częścią pracy magisterskiej pt. <br>\"Metody usprawniania wyników klasyfikacji w problemie wykrywania bankrutujących przedsiębiorstw\". \n",
    "<br>\n",
    "W notatniku zamieszczono kod napisany w języku R wykorzystany do wykonania większości obliczeń zamieszczonych w pracy magisterskiej.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Wczytywanie danych i pakietów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(tidyverse)\n",
    "library(mice)\n",
    "library(caret)\n",
    "library(gbm)\n",
    "library(VIM)\n",
    "library(MLmetrics)\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wczytanie danych, zmiana nazw kolumn, konwersja zmiennej Y z int -> factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.csv(\"bankrut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(df) <- c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"X11\", \"X12\", \"X13\", \"X14\", \"X15\", \"X16\", \"X17\",\n",
    "                  \"X18\", \"X19\", \"X20\", \"X21\", \"X22\", \"X23\", \"X24\", \"X25\", \"X26\", \"X27\", \"X28\", \"X29\", \"X30\", \"X31\", \"X32\",\n",
    "                  \"X33\", \"X34\", \"X35\", \"X36\", \"X37\", \"X38\", \"X39\", \"X40\", \"X41\", \"X42\", \"X43\", \"X44\", \"X45\", \"X46\", \"X47\", \n",
    "                  \"X48\", \"X49\", \"X50\", \"X51\", \"X52\", \"X53\", \"X54\", \"X55\", \"X56\", \"X57\", \"X58\", \"X59\", \"X60\", \"X61\", \"X62\", \n",
    "                  \"X63\", \"X64\", \"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df$Y <- as.factor(df$Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Brakujące dane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zliczenie brakujących danych w każdej zmiennej oraz zapis do tabeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nulls = sapply(df, function(x) sum(is.na(x)))\n",
    "df_nh = df_nulls[df_nulls>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = data_frame(Attribute = as.character(names(df_nh)), Nr_of_NaNs=df_nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram zmiennych  posiadających > 200 NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nh = df_nulls[df_nulls>200]\n",
    "df_nan = data_frame(Attribute = as.character(names(df_nh)), Nr_of_NaNs=df_nh)\n",
    "df_nan$Attribute = factor(df_nan$Attribute, levels = df_nan$Attribute[order(-df_nan$Nr_of_NaNs)])\n",
    "ggplot(df_nan, aes(Attribute, Nr_of_NaNs)) + theme_bw() + geom_bar(stat = \"identity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Opcjonalnie: Zliczanie wierszy, w których występują NA oraz ich usunięcie*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_na <- apply(df, 1, function(x){any(is.na(x))})\n",
    "sum(row_na)\n",
    "df_filtered <- df[!row_na,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Opcjonalnie: Tworzenie dataframe, w którym liczba NA w wierszu nie przekracza 5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_5 <- df[!rowSums(is.na(df)) > 5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Wartości odstające (outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosowano 2 różne metody eliminujące wartości odstające.<br>\n",
    "1) Usunięcie i wstawienie NA, w późniejszym stadium zostaną uzupełnione za pomocą imputacji<br>\n",
    "2) Usunięcie i wstawienie wartości z 95 lub 5 percentyla.<br>\n",
    "\n",
    "Z uwagi na specyfikę danych (bardzo duża wariancja występująca w większości zmiennych) użyto szerokiego marginesu wykrywania -\n",
    "10IQR. Standardowa miara 1,5IQR zaklasyfikowałaby zbyt dużo wartości jak outlier. <br>\n",
    "Za wartości odstające uznane zostały: x < Q1 - 10 x IQR lub x > Q3 + 10 x IQR <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wariancja każdej ze zmiennych (z wyłączeniem Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = apply(df[-65], 2, var, na.rm = TRUE)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wyświetlanie wariancji dla kolumn, gdzie var > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(var[var>100], digits=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przygotowanie zmiennych oraz tabeli zliczających wartości odstające"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out1 = df\n",
    "df_out2 = df\n",
    "\n",
    "count_outliers <- data.frame(Attribute=character(), \n",
    "                          Nr_of_outlier=double(),\n",
    "                          stringsAsFactors = FALSE)\n",
    "\n",
    "count_outliers2 <- data.frame(Attribute=character(), \n",
    "                          Nr_of_outlier=double(),\n",
    "                          stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metoda 1 - wstawianie za outlier -> NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in which(sapply(df, is.numeric))) {\n",
    "  \n",
    "  q = quantile(df[i], na.rm=TRUE)\n",
    "  iqr = IQR(as.numeric(unlist(df[i])), na.rm=TRUE)\n",
    "  up_limit = as.numeric(q[\"75%\"]) + (10*iqr)\n",
    "  down_limit =  as.numeric(q[\"25%\"]) - (10*iqr)\n",
    "  limits = c(up_limit, down_limit)\n",
    "  sum_out = sum(df[i]<down_limit | df[i]>up_limit, na.rm=TRUE)\n",
    "  count_outliers[nrow(count_outliers) + 1,]= list(as.character(names(df[i])), sum_out)\n",
    "  \n",
    "  for (j in which(df[i]<down_limit | df[i]>up_limit)) {\n",
    "    df_out1[j, i] <- NA\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suma znalezionych outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(count_outliers$Nr_of_outlier)\n",
    "count_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metoda 2 - wstawianie za outlier -> 5th albo 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in which(sapply(df, is.numeric))) {\n",
    "  \n",
    "  qnt <- quantile(df[i], probs=c(.25, .75), na.rm = T)\n",
    "  outer_qnt <- quantile(df[i], probs=c(.05, .95), na.rm = T)\n",
    "  H <- 10 * IQR(as.numeric(unlist(df[i])), na.rm = T)\n",
    "  up_limit = qnt[2] + H\n",
    "  down_limit =  qnt[1] - H\n",
    "  sum_out = sum(df[i]<down_limit | df[i]>up_limit, na.rm=TRUE)\n",
    "  results_outliers2[nrow(results_outliers2) + 1,]= list(as.character(names(df[i])), sum_out)\n",
    "  \n",
    "  for (j in which(df[i]<down_limit | df[i]>up_limit)) {\n",
    "    df_out2[j, i][df_out2[j, i] < (qnt[1] - H)] <- outer_qnt[1]\n",
    "    df_out2[j, i][df_out2[j, i] > (qnt[2] + H)] <- outer_qnt[2]\n",
    "  }\n",
    "}\n",
    "sum(results_outliers2$Nr_of_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Imputacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputacji poddano 3 zbiory otrzymane we wcześniejszych punktach:<br>\n",
    "**df** - oryginalny zbiór zawierający outliers<br>\n",
    "**df_out1** - zbiór z usuniętymi outliers i wstawionymi NA<br>\n",
    "**df_out2** - zbiór z usuniętymi outliers i wstawionymi wartościami z 5 lub 95 percentyla<br><br>\n",
    "Na każdym z nich wykonany 5 różnych metod imputacji:<br>\n",
    "1) Uzupełnienie medianą (obliczona osobno dla każdej z klas)<br>\n",
    "2) Algorytm k-NN<br>\n",
    "3) Hot-Deck<br>\n",
    "4) Imputacja wielokrotna<br>\n",
    "5) Imputacja wielokrotna uśredniona<br><br>\n",
    "Poniżej przedstawiono imputację dla zbioru **df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Mediana warunkowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med = df\n",
    "if_row_nan = df_med[, \"Y\"] == df_med[j, \"Y\"]\n",
    "for (i in which(sapply(df_med, is.numeric))) {\n",
    "  for (j in which(is.na(df_med[, i]))) {\n",
    "    df_med[j, i] <- median(df_med[if_row_nan, i],  na.rm = TRUE)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Algorytm k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k = preProcess(df, method = c(\"knnImpute\"), k=3)\n",
    "df_knn = predict(df_k, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Hot-Deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot = hotdeck(df, imp_var = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Imputacja wielokrotna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp <- mice(df, m = 5, maxit = 10,  seed = 8, method = 'pmm')\n",
    "df_mice = complete(imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Imputacja wielokrotna uśredniona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice_mean = df\n",
    "\n",
    "for(i in 1:5){\n",
    "  assign(paste(\"df_mice\", i, sep = \"\"), complete(imp, i))    \n",
    "}\n",
    "\n",
    "for (i in which(sapply(df, is.numeric))) {\n",
    "  for (j in which(is.na(df_mice_mean[, i]))) {\n",
    "    df_mice_mean[j, i] <- ((df_mice1[j, i] + df_mice2[j, i] + \n",
    "                            df_mice3[j, i] + df_mice4[j, i] + df_mice5[j, i])/5)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Skalowanie \n",
    "\n",
    "#### Metoda standaryzacji - sprowadzenie zmiennych do rozkładu (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_med\n",
    "df_s = preProcess(df_med, method = c(\"center\", \"scale\"))\n",
    "df_med = predict(df_s, df_med)\n",
    "\n",
    "#df_knn\n",
    "df_k = preProcess(df_knn, method = c(\"center\", \"scale\"))\n",
    "df_knn = predict(df_k, df_knn)\n",
    "\n",
    "#df_hot\n",
    "df_h = preProcess(df_hot, method = c(\"center\", \"scale\"))\n",
    "df_hot = predict(df_s, df_hot)\n",
    "\n",
    "#df_mice\n",
    "df_m = preProcess(df_mice, method = c(\"center\", \"scale\"))\n",
    "df_mice = predict(df_m, df_mice)\n",
    "\n",
    "#df_mice_mean\n",
    "df_mm = preProcess(df_mice_mean, method = c(\"center\", \"scale\"))\n",
    "df_mice_mean = predict(df_mm, df_mice_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Przygotowanie zbiorów\n",
    "Ze względu na późniejsze wykonywanie klasyfikacji na 15 różnych zbiorach danych, zbiory te umieszczono dla ułatwienia w jednej liście elementów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list(df_med, df_knn, df_hot, df_mice, df_mice_mean,\n",
    "               df_out1_med, df_out1_knn, df_out1_hot, df_out1_mice, df_out1_mice_mean,\n",
    "               df_out2_med, df_out2_knn, df_out2_hot, df_out2_mice, df_out2_mice_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie postąpiono z nazwami zmiennych, metodami imputacji oraz usuwania outlierów. Ułatwi to wprowadzanie do tabeli wyników informacji na temat specyfiki danego zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_names = c(\"df_med\", \"df_knn\", \"df_hot\", \"df_mice\", \"df_mice_mean\",\n",
    "                  \"df_out1_med\", \"df_out1_knn\", \"df_out1_hot\", \"df_out1_mice\", \"df_out1_mice_mean\",\n",
    "                  \"df_out2_med\", \"df_out2_knn\", \"df_out2_hot\", \"df_out2_mice\", \"df_out2_mice_mean\",\n",
    "                  \"df\", \"df_out1\", \"df_out2\")\n",
    "\n",
    "df_list_imputation = c(\"mediana\", \"knn\", \"hotdeck\", \"mice\", \"mice_mean\",\n",
    "                       \"mediana\", \"knn\", \"hotdeck\", \"mice\", \"mice_mean\",\n",
    "                       \"mediana\", \"knn\", \"hotdeck\", \"mice\", \"mice_mean\",\n",
    "                       \"brak\", \"brak\", \"brak\")\n",
    "\n",
    "df_list_outliers = c(\"brak\", \"brak\", \"brak\", \"brak\", \"brak\",\n",
    "                    \"nan\", \"nan\", \"nan\", \"nan\", \"nan\",\n",
    "                    \"5_95\", \"5_95\", \"5_95\", \"5_95\", \"5_95\", \n",
    "                    \"brak\", \"nan\", \"5_95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Analiza imputacji na podstawie zmiennych X37 oraz X21\n",
    "Zmienne te posiadają najwięcej wartości pustych, dlatego też warto poddać analizie jej rozkład przed i po zastosowaniu imputacji<br>\n",
    "Poniżej kod dla zmiennej X37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabele zapisujące średnie i odchylenia standardowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_x37 <- data.frame(Metoda = character(),\n",
    "                          Imputacja = character(),\n",
    "                          Outliers = character(),\n",
    "                          mean_0 = double(),\n",
    "                          mean_all = double(),\n",
    "                          mean_1 = double(),\n",
    "                          sd_0 = double(),\n",
    "                          sd_all = double(),\n",
    "                          sd_1 = double(),\n",
    "                          stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja do_estim_X37() \n",
    "Oblicza średnie i odchylenia standardowe zmiennej X37 dla każdej klasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_estim_X37 = function(df_input, dfname, imputation, outliers){\n",
    "  # Z wybranego zbioru zwraca średnią i odchylenie zmiennej X37 dla kazdej klasy\n",
    "  mean_0 = mean(df_input$X37[df_input$Y == 0], na.rm = TRUE)\n",
    "  mean_all = mean(df_input$X37, na.rm = TRUE)\n",
    "  mean_1 = mean(df_input$X37[df_input$Y == 1], na.rm = TRUE)\n",
    "  sd_0 = sd(df_input$X37[df_input$Y == 0], na.rm = TRUE)\n",
    "  sd_all = sd(df_input$X37, na.rm = TRUE)\n",
    "  sd_1 = sd(df_input$X37[df_input$Y == 1], na.rm = TRUE)\n",
    "  means_X37 = list(dfname, imputation, outliers, mean_0, mean_all, mean_1, sd_0, sd_all, sd_1)\n",
    "  means_X37\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pętla obliczająca statystyki dla każdego z 18 zbiorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 1:18) {\n",
    "  results_x37[nrow(results_x37) + 1,] = do_estim_X37(df_list[[i]], df_list_names[i], \n",
    "                                                     df_list_imputation[i], df_list_outliers[i])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Tabele i funkcje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapisywanie otrzymanych wyników w przejrzysty i praktyczny (pozwalający na wykorzystanie w dalszej analizie sposób wymaga stworzenia odpowiednych tabel typu dataframe. Ponadto niezbędne stały się funkcje umożliwiające korzystanie z niestandardowych miar ocen jakości klasyfikacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Zapisywanie wyników klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabela zbierająca wyniki klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results <- data.frame(Metoda = character(),\n",
    "                      Imputacja = character(),\n",
    "                      Outliers = character(),\n",
    "                      AUC_train_MN = double(),\n",
    "                      AUC_train_SD = double(),\n",
    "                      AUC = double(),\n",
    "                      Recall_train_MN = double(),\n",
    "                      Recall_train_SD = double(),\n",
    "                      Recall = double(),\n",
    "                      F1 = double(),\n",
    "                      Kappa = double(),\n",
    "                      Zbiór = character(),\n",
    "                      Trening = character(),\n",
    "                      Parametry = character(),\n",
    "                      stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja dodajWynik()\n",
    "Odpowiada za zapisywanie do tabeli **results** wszystkich niezbędnych w dalszej analizie parametrów klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dodajWynik <- function(input_frame, impute_method, outlier_method, model, modelControl, matCon){\n",
    "  \n",
    "  cvString <- paste(modelControl$number,modelControl$method, sep=\"-\")\n",
    "  \n",
    "  bT = model$bestTune\n",
    "  col_bT = colnames(bT)\n",
    "  c = list()\n",
    "  for (i in 1:ncol(model$bestTune)){\n",
    "    c[i] = paste(col_bT[i], bT[i], sep=\": \")\n",
    "  }\n",
    "    \n",
    "  tuneString <- paste(c[1], c[2], c[3], c[4], sep = \" / \")\n",
    "\n",
    "  results[nrow(results) + 1,] <<- list(model$method,\n",
    "                                    impute_method,\n",
    "                                    outlier_method,\n",
    "                                    round(mean(model$resample$ROC), digits = 4),\n",
    "                                    round(sd(model$resample$ROC), digits = 4),\n",
    "                                    round(auc_test, digits = 4),\n",
    "                                    round(mean(model$resample$Recall), digits = 4),\n",
    "                                    round(sd(model$resample$Recall), digits = 4),\n",
    "                                    round(matCon$byClass['Recall'], digits = 4), \n",
    "                                    round(matCon$byClass['F1'], digits = 4), \n",
    "                                    round(matCon$overall['Kappa'], digits = 4),\n",
    "                                    input_frame, \n",
    "                                    cvString,\n",
    "                                    tuneString)\n",
    "  print(\"Dodano wynik do tabeli\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Miary oceny klasyfikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja metricSummary()\n",
    "Modyfikacja domyślnej funkcji **twoClassSummary()**, która znajduje się w pakiecie **caret**. Zmianie w stosunku do pierwotnej funkcji uległa kolejność pobierania z danych klasy pozytywnej (1) i negatywnej(0) oraz dodano inne miary klasyfikacji stosowane w uczeniu klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MLmetrics)\n",
    "\n",
    "metricSummary <- function(data, lev = NULL, model = NULL){\n",
    "  \n",
    "  lvls <- levels(data$obs)\n",
    "  \n",
    "  if (length(lvls) > 2) \n",
    "    stop(paste(\"Your outcome has\", length(lvls), \"levels. The twoClassSummary() function isn't appropriate.\"))\n",
    "  \n",
    "  caret:::requireNamespaceQuietStop(\"ModelMetrics\")\n",
    "  \n",
    "  if (!all(levels(data[, \"pred\"]) == lvls)) \n",
    "    stop(\"levels of observed and predicted data do not match\")\n",
    "  \n",
    "  data$y = as.numeric(data$obs == lvls[2])\n",
    "  rocAUC <- ModelMetrics::auc(ifelse(data$obs == lvls[1], 0, 1), data[, lvls[2]])\n",
    "    \n",
    "  out <- c(rocAUC, \n",
    "           sensitivity(data[, \"pred\"], data[, \"obs\"], lvls[2]), \n",
    "           specificity(data[, \"pred\"], data[, \"obs\"], lvls[1]),\n",
    "           recall(data[, \"pred\"], data[, \"obs\"], lvls[2])\n",
    "           F1_Score(y_pred = data[, \"pred\"], y_true = data[, \"obs\"], positive = lvls[2]))\n",
    "  )\n",
    "    \n",
    "  names(out) <- c(\"ROC\", \"Sens\", \"Spec\", \"Recall\", \"F1\")\n",
    "  out\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja oblicz_auc()\n",
    "Funkcja obliczająca miarę **AUC** dla danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oblicz_auc <- function(y_predicted_probs, df_labels){\n",
    "  \n",
    "  roc_pred = prediction(predictions = y_predicted_probs$X1, labels = df_labels$Y)\n",
    "  perf = performance(roc_pred, measure = 'tpr', x.measure = 'fpr')\n",
    "  perf.auc = performance(roc_pred, measure = \"auc\")\n",
    "  auc_val = unlist(perf.auc@y.values)\n",
    "  \n",
    "  auc_val\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Klasyfikacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omówienie schematu algorytmu na przykładzie klasyfikatora gbm oraz zbioru df_med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie danych, podział na zbiory testowe i treningowe oraz podział na zmienne wejściowe (X1 - X64) i zmienną wyjściową (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e = df_med\n",
    "\n",
    "trainIndex = createDataPartition(df_e$Y, p=0.8, list=FALSE)\n",
    "df_train = df_e[trainIndex,]\n",
    "df_test = df_e[-trainIndex,]\n",
    "X_train = df_train[,1:ncol(df_e)-1]\n",
    "y_train = df_train$Y\n",
    "X_test = df_test[,1:ncol(df_e)-1]\n",
    "y_test = df_test$Y\n",
    "\n",
    "levels(df_train$Y) <- c('X0', 'X1')\n",
    "levels(df_test$Y) <- c('X0', 'X1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja trainControl() pozwala na kontrolowanie treningu oraz zastosowanie metod próbkowania danych w procesie uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmControl = trainControl(method = \"cv\",\n",
    "                          number = 5,\n",
    "                          search = \"grid\",\n",
    "                          classProbs = TRUE,\n",
    "                          summaryFunction = metricSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja expan.grid() daje możliwość sprecyzowania hiperparametrów wprowadzanych do modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmGrid = expand.grid(interaction.depth = 9,\n",
    "                      n.trees = 500,\n",
    "                      shrinkage = 0.10,\n",
    "                      n.minobsinnode = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja train() służy do treningu danego klasyfikatora. Przekazane zostają do niej wcześniej wspomniane funkce trainControl() oraz expand.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = train(Y ~ ., data = df_train, \n",
    "                      method = \"gbm\",\n",
    "                      trControl = gbmControl,\n",
    "                      tuneGrid = gbmGrid,\n",
    "                      metric = 'Recall',\n",
    "                      na.action = na.pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie predykcji dla danych testowych oraz obliczenie prawdopodobieństw potrzebnych do obliczenia miary AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(gbm, df_test, na.action = na.pass)\n",
    "y_pred_probs = predict(gbm, df_test, type=\"prob\", na.action = na.pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stworzenie macierzy pomyłek na podstawie predykcji dla danych testowych oraz rzeczywistych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_test = confusionMatrix(reference = df_test$Y, data = y_pred, mode = 'everything', positive = 'X1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uśredniona macierz pomyłek dla danych treningowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_train_cv = confusionMatrix(gbm, \"average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczenie miary AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test = oblicz_auc(y_pred_probs, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conf_train_cv)\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapisywanie wyników klasyfikacji do tabeli **results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dodajWynik(df_med, mediana, gbm, gbmControl, conf_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
